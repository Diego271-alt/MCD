---
title: ""
author: ""
date: ""
output: pdf_document
header-includes:
  - \usepackage[spanish]{babel}
  - \usepackage{graphicx}
  - \usepackage{titling}
  - \usepackage{lipsum}
  - \usepackage{geometry}
  - \geometry{margin=1in}
  - \usepackage{multicol}
  - \usepackage{indentfirst}
  - \setlength{\parindent}{2em}
  - \setlength{\columnsep}{1cm}
  - \usepackage{ragged2e}
  - \usepackage{natbib}
  - \bibliographystyle{apalike}
  - \usepackage{subcaption}
---

\vspace{2cm}  

\begin{flushleft}
    \begin{minipage}{0.2\textwidth}
        \includegraphics[width=3cm]{assets/utm.png}
    \end{minipage}
    \begin{minipage}{0.75\textwidth}
        \raggedright
        \LARGE UNIVERSIDAD TECNOLÓGICA DE LA MIXTECA  \\
        \Large MAESTRÍA EN CIENCIA DE DATOS  \\
        \normalsize CLAVE DGP: 200089
    \end{minipage}
\end{flushleft}

\vspace{3cm}  

\begin{center}
    \LARGE 371023 Visualización de datos\\
    \Large Examen Segundo Parcial\\
    \large Dr. José del Carmen Jiménez Hernández
\end{center}

\vspace{5cm}  

\begin{center}
    \Large Lic. José Ricardo Mendoza Villar\\
    \large 2024370008
\end{center}

\vspace{5cm}  

\begin{center}
    \large 19 de mayo de 2025\\
    \large Semestre 2025B
\end{center}
\newpage

```{r, echo=FALSE}
# Importar paquetes
suppressPackageStartupMessages(library(sf))
suppressPackageStartupMessages(library(maps))
suppressPackageStartupMessages(library(datos))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(scales))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(lubridate))
```

### Bibliotecas
```{r, eval=FALSE}
# Importar paquetes
library(sf)
library(maps)
library(datos)
library(dplyr)
library(scales)
library(stringr)
library(ggplot2)
library(lubridate)
```

### Funciones
```{r}
# Esta funcion permite cambiar la codificacion de las columnas
# que sean strings en utf-8 (para mantener acentos)
string_utf8 <- function(dataframe) {
  dataframe[] <- lapply(dataframe, function(x) {
    if (is.character(x)) {
      iconv(x, from = "latin1", to = "UTF-8")
    } else {
      return(x)
    }
  })
  return(dataframe)
}
```

\section*{Ejercicio 1}
Descarga la base de datos de temperatura máxima y mínima disponible en <https://www.gits.igg.unam.mx/idea/descarga> (o de algun otro sitio que considere apropiado, por ejemplo el INEGI). Elabora un mapa que muestre dichas temperaturas para la república mexicana. Que paleta de colores cree más conveniente para cada mapa?
```{r fig.width=8, fig.height=6, warning=FALSE}
maximo <- read_sf("data/inegi_conttempma_1998.shp")
maximo <- string_utf8(maximo)

maximo <- maximo %>%
  mutate(
    temp_inf = as.numeric(str_extract(tmax_rango, "\\d+(?=\\xb0)")),
    temp_sup = case_when(
      str_detect(tmax_rango, "Menor de") ~
        as.numeric(str_extract(tmax_rango, "-?\\d+(?=°)")),
      str_detect(tmax_rango, "Más de") ~
        as.numeric(str_extract(tmax_rango, "-?\\d+(?=°)")),
      str_detect(tmax_rango, "a") ~
        as.numeric(str_extract(str_extract(tmax_rango, "a\\s?-?\\d+°"), "-?\\d+(?=°)")),
      TRUE ~ NA_real_
    )
  ) %>%
  mutate(
    temp_prom = case_when(
      !is.na(temp_inf) & !is.na(temp_sup) ~ (temp_inf + temp_sup) / 2,
      !is.na(temp_inf) ~ temp_inf,
      !is.na(temp_sup) ~ temp_sup,
      TRUE ~ NA_real_
    )
  )

ggplot(data = maximo) +
  geom_sf(mapping = aes(fill = temp_prom)) +
  scale_fill_gradient(low = "yellow", high = "red") +
  theme_minimal() +
  labs(title = "Mapa de temperaturas máximas en México",
       fill = "Temperatura (°C)")
```

```{r, warning=FALSE}
minimo <- read_sf("data/inegi_conttempmi_1998.shp")
minimo <- string_utf8(minimo)

minimo <- minimo %>%
  mutate(
    temp_inf = as.numeric(str_extract(tmin_rango, "(?<=de\\s?)(-?\\d+)(?=°)")),
    temp_sup = case_when(
      str_detect(tmin_rango, "Menor de") ~
        as.numeric(str_extract(tmin_rango, "-?\\d+(?=°)")),
      str_detect(tmin_rango, "Más de") ~
        as.numeric(str_extract(tmin_rango, "-?\\d+(?=°)")),
      str_detect(tmin_rango, "a") ~
        as.numeric(str_extract(str_extract(tmin_rango, "a\\s?-?\\d+°"), "-?\\d+(?=°)")),
      TRUE ~ NA_real_
    )
  ) %>%
  mutate(
    temp_prom = case_when(
      !is.na(temp_inf) & !is.na(temp_sup) ~ (temp_inf + temp_sup) / 2,
      !is.na(temp_inf) ~ temp_inf,
      !is.na(temp_sup) ~ temp_sup,
      TRUE ~ NA_real_
    )
  )

ggplot(data = minimo) +
  geom_sf(mapping = aes(fill = temp_prom)) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  theme_minimal() +
  labs(title = "Mapa de temperaturas mínimas en México",
       fill = "Temperatura (°C)")
```

Para ambos conjuntos de datos, se contaba con una columna de temperatura de tipo texto (tmin_rango y tmax_rango), la primera función que se les aplica a cada conjunto de datos permite cambiar la codificación a utf-8 para respertar los símbolos especiales como: °, después noté que esta columna en general presentaba diferentes valores que no se podían extraer con una única expresión regular, había valores con cadenas que decían: "de 20° a 24° C", "Más de 20° C", "Menor de -4° C", por lo que fue necesario utilizar varias condiciones para extraer los valores, al ser un intervalo de valores, como se deseaba tener una escala de temperatura, para lograr esto se requiere de un valor único y no de un intervalo o cadena de texto, por lo que a las cadenas con un intervalo se les colocó el promedio y a las que solo tenían un valor se les colocó ese valor, respecto a la paleta de colores, para las temperaturas máximas opté por una escala de amarillo a rojo y para la mínima de azul oscuro a azul claro, bastante influenciado por los colores que he visto desde que era pequeño y que en lo general he visto que con azul oscuro se representan temperaturas frias y con rojo temperaturas altas (lo habitual en mapas de calor).

\section*{Ejercicio 2}
Descarga los datos más recientes sobre el programa presupuestario S191 del Gobierno Federal disponible en <https://www.datos.gob.mx/dataset/programa_presupuestario_s191>. Elabora un mapa sobre la distribución de los recursos a nivel nacional.

Para comenzar, es necesario contar con un mapa de las entidades federativas de México, por lo que tomé el mapa de estados de la misma página del **Ejercicio 1**:

```{r, warning=FALSE}
mexico <- read_sf("data/gdb_ref_esta_ine_2009.shp")
mexico <- string_utf8(mexico)
mexico <- mexico %>%
  mutate(
    nom_ent = toupper(
      case_when(
        (nom_ent == "Distrito Federal") ~ "Ciudad de México",
        TRUE ~ nom_ent
      )
    )
  )
```

Para esta primer sección fue necesario homologar los nombres de las entidades federativas, como el mapa es de 2009 la Ciudad de México aparece como Distrito Federal, por lo que el case_when permite hacer el cambio del valor, también se puso todo el texto en mayúsculas para una manipulación más sencilla y codificar en utf-8 para respetar los acentos.

```{r, warning=FALSE}
prog_presupues_s191_2023 <- read.csv("data/programa_presupuestario_s191_2023.csv")
# Eliminar aquellos programas sin un estado asingado
prog_presupues_s191_2023 <- prog_presupues_s191_2023 %>%
  filter(
    (prog_presupues_s191_2023$entidad_federativa_institucion_de_adscripcion
    != "EXCEPTUADO CONFORME AL ARTÍCULO 28 FRACCIÓN I DEL REGLAMENTO SNII") &
    (prog_presupues_s191_2023$entidad_federativa_institucion_de_adscripcion
    != "SIN INSTITUCIÓN")
  )
```

Para el conjunto de datos se hizo una limpieza para mantener unicamente los programas presupuestales con información con su entidad federativa.

```{r, warning=FALSE}
prog_presupues_s191_2023_por_estado <- prog_presupues_s191_2023 %>%
  group_by(entidad_federativa_institucion_de_adscripcion) %>%
  summarise(
    monto_recursos = sum(
      coalesce(monto_anual_entregado_por_distincion, 0) +
      coalesce(monto_apoyos_adicionales, 0)
    )
  )
```

Como existen varios programas presupuestales por estado, es necesario agrupar los datos por estado y realizar la suma de los montos otorgados, esto produce un registro único por estado con el monto total otorgado

```{r, warning=FALSE}
mapa_recursos <- mexico %>%
  left_join(
    prog_presupues_s191_2023_por_estado,
    by = c("nom_ent" = "entidad_federativa_institucion_de_adscripcion")
  )
```

Finalmente para la parte de manipulación de datos, se hace un cruce entre el mapa y los datos presupuestales agrupados por las columnas de estado en cada tabla.

```{r, warning=FALSE}
ggplot(data = mapa_recursos) +
  geom_sf(aes(fill = monto_recursos)) +
  scale_fill_gradient2(
    low = "red", mid = "white", high = "darkgreen",
    name = "Monto de Recursos",
    labels = label_dollar(prefix = "$")
  ) +
  labs(
    title = "Distribución de los Recursos del Programa Presupuestario S191",
  )
```
Este mapa me pareció muy interesante, ya que para generarlo realicé varias iteraciones, en las primeras que hice, el mapa se veia más distribuido en la asignación de presupuesto, pero era porque la Ciudad de México tiene un nombre distinto en ambos conjuntos de datos, una vez arreglado ese error, me di cuenta de la diferencia notable que tiene la Ciudad de México respecto al resto de estados, otro aprendizaje valioso que me llevo es el tema de la coloración, inicialmente utilicé una escala de verde claro a verde oscuro, pero justo por las tonalidades no se apreciaba a disntiguir las diferencias presupuestales entre el resto de estado, hasta que incluí el degradado blanco y en consecuencia los colores son más tenues, en general el mapa muestra bastante más claro las diferencias.

\section*{Ejercicio 3}
El paquete **datos** (ya lo hemos usado en clase) contiene una base de datos sobre vuelos que despegaron de Nueva York (JFK, LGA o EWR) durante 2013. 

- Elabore una grafica donde se visualice la distribución de las horas de salida durante el año, usando: el mes y año completo en la etiqueta de la escala.  
```{r, warning=FALSE}
vuelos_process <- vuelos %>%
  filter(
    origen %in% c("JFK", "LGA", "EWR"),
    anio == 2013
  ) %>%
  mutate(
    anio_mes = factor(
      paste(anio, mes, sep = "-"),
      levels = paste(2013, 1:12, sep = "-")
    ),
    hora_salida = floor(horario_salida / 100) + (horario_salida %% 100) / 60,
  )

ggplot(vuelos_process, aes(x = hora_salida)) +
  geom_histogram(bins = 24, fill = "skyblue", color = "black") +
  facet_wrap(~ anio_mes) +
  labs(
    title = "Distribución de las horas de salida durante 2013",
    x = "Hora de salida",
    y = "Frecuencia"
  )+
  scale_x_continuous(limits = c(0, 24), breaks = seq(0, 24, by = 3)) +
  theme_minimal()
```

- Elabore una grafica donde se visualice la distribución de las horas de salida durante el año, usando: el mes abreviado y año completo en la etiqueta de la escala.

```{r, warning=FALSE}
vuelos_process2 <- vuelos %>%
  filter(
    origen %in% c("JFK", "LGA", "EWR"),
    anio == 2013
  ) %>%
  mutate(
    mes = factor(
      mes,
      levels = 1:12,
      labels = c(
        "Ene", "Feb", "Mar", "Abr",
        "May", "Jun", "Jul", "Ago",
        "Sep", "Oct", "Nov", "Dic"
      )
    ),
    anio_mes_compact = paste(anio, mes, sep = "-"),
    hora_salida = floor(horario_salida / 100) + (horario_salida %% 100) / 60,
  )

ggplot(vuelos_process2, aes(x = hora_salida)) +
  geom_histogram(bins = 24, fill = "skyblue", color = "black") +
  facet_wrap(~anio_mes_compact) +
  labs(
    title = "Distribución de las horas de salida durante 2013",
    x = "Hora de salida",
    y = "Frecuencia"
  )+
  scale_x_continuous(limits = c(0, 24), breaks = seq(0, 24, by = 3)) +
  theme_minimal()
```

- Elabore una grafica donde se visualice la distribución de las horas de salida durante el 14 de febrero de 2013, usando el mes completo en la etiqueta de la escala.

```{r, warning=FALSE}
vuelos_feb_14 <- vuelos %>%
  filter(
    origen %in% c("JFK", "LGA", "EWR"),
    anio == 2013,
    mes == 2,
    dia == 14
  ) %>%
  mutate(
    hora_salida = floor(horario_salida / 100) + (horario_salida %% 100) / 60
  )

ggplot(vuelos_feb_14, aes(x = hora_salida)) +
  geom_histogram(bins = 24, fill = "skyblue", color = "black") +
  labs(
    title = "Distribución de las horas de salida del 14 de febrero de 2013",
    x = "Hora de salida",
    y = "Frecuencia"
  ) +
  scale_x_continuous(limits = c(0, 24), breaks = seq(0, 24, by = 1)) +
  theme_minimal()
```

\section*{Ejercicio 4}
Usando lo base de datos sobre vuelos y diamantes del paquete **datos**.

- ¿Cómo cambia la distribución de las horas de los vuelos dentro de un día a lo largo del año?
```{r, warning=FALSE}
vuelos_day <- vuelos %>%
  filter(
    origen %in% c("JFK", "LGA", "EWR"),
    anio == 2013,
    mes == 3
  ) %>%
  mutate(
    hora_salida = floor(horario_salida / 100) + (horario_salida %% 100) / 60
  )
vuelos_mar_12 <- vuelos_day %>% filter(dia == 12)
vuelos_mar_13 <- vuelos_day %>% filter(dia == 13)
vuelos_mar_14 <- vuelos_day %>% filter(dia == 14)

ggplot() +
  geom_histogram(
    data = vuelos_mar_12, aes(x = hora_salida),
    bins = 24, fill = "blue", color = "black"
  ) +
  geom_histogram(
    data = vuelos_mar_13, aes(x = hora_salida),
    bins = 24, fill = "red", color = "black", alpha = 0.5
  ) +
  geom_histogram(
    data = vuelos_mar_14, aes(x = hora_salida),
    bins = 24, fill = "green", color = "black", alpha = 0.5
  ) +
  labs(
    title = "Distribuciones de las horas de salida del 12, 13 y 14 de marzo de 2013",
    x = "Hora de salida",
    y = "Frecuencia"
  ) +
  scale_x_continuous(limits = c(0, 24), breaks = seq(0, 24, by = 1)) +
  theme_minimal()
```
Al comparar la distribución de 3 días distintos se puede apreciar que las distribuciones de los datos son muy similares entre si, de hecho tienen mucho parecido con las distribuciones por mes del ejercicio anterior, hay ligeras variaciones, pero particularmente nada extremo que de la apariencia de que los vuelos tienen distribuciones distintas, se ve un paro de labores entre la 1:30 y 4:30 hrs, seguramente algún periodo de mantenimiento (que siendo realistas seria complicado llenar un vuelo en esos horarios y seguramente tampoco resulte rentable tener ese tipo de vuelos).

- Compara `horario_salida`, `salida_programada` y `atraso_salida`. ¿Son consistentes? Explica tus hallazgos.
```{r, warning=FALSE}
vuelos_comparacion <- vuelos %>%
  filter(
    origen %in% c("JFK", "LGA", "EWR"),
    anio == 2013
  ) %>%
  mutate(
    hora_salida = ymd_hm(paste(
      anio, mes, dia,
      floor(horario_salida / 100), horario_salida %% 100,
      sep = "-"
    )),
    hora_salida_prog = ymd_hm(paste(
      anio, mes, case_when(
        (horario_salida < salida_programada) & (atraso_salida > 0) ~ dia - 1,
        TRUE ~ dia
      ),
      floor(salida_programada / 100), salida_programada %% 100,
      sep = "-"
    )),
    atraso_salida_calculado = as.numeric(difftime(hora_salida, hora_salida_prog, units = "mins"))
  )

ggplot(vuelos_comparacion, aes(x = salida_programada, y = horario_salida)) +
  geom_hex(bins = 100) +
  labs(
    title = "Comparación de horario de salida y salida programada",
    x = "Salida Programada",
    y = "Horario de Salida"
  ) +
  theme_minimal()

# Comparar la variable atraso_salida con la diferencia calculada
ggplot(vuelos_comparacion, aes(x = atraso_salida_calculado, y = atraso_salida)) +
  geom_point() +
  labs(
    title = "Comparación de atraso de salida calculado vs real",
    x = "Atraso de Salida Calculado",
    y = "Atraso de Salida"
  ) +
  theme_minimal()
```
En general el horario de salida vs salida programda muestra cierto patrón en los datos, la gráfica tiene cierta armonía, del lado inferior derecho pareciera que hay unos datos aislados, pero es parte de la naturaleza de manipular el tiempo (que tiene naturaliza modular, es decir, de las 24hrs pasamos a las 00 hrs), si calculamos la diferencia entre el horario de salida y la salida programada obtenemos un atraso de la salida real, y si la comparamos contra la estimación del atrasado de la salida, de hecho es muy notorio una relación practicamente lineal, es decir, las estimaciones son muy congruentes contra el atrasado verdadero, seguramente esos datos aislados en la comparación de salida sean ocasionados por fenómenos naturales como alguna especie de ciclón o huracán que generen retrasos prolongados en las salidas de los vuelos.

- Compara `tiempo_vuelo` con la duración entre la salida y la llegada. Explica tus hallazgos. (Pista: considera la ubicación del aeropuerto).
```{r, warning=FALSE}
vuelos_comparacion_tiempo <- vuelos %>%
  filter(
    origen %in% c("JFK", "LGA", "EWR"),
    anio == 2013
  ) %>%
  mutate(
    horario_llegada_dt = ymd_hm(paste(
      anio, mes,
      case_when(
        (horario_llegada < horario_salida) ~ dia + 1,
        TRUE ~ dia
      ),
      floor(horario_llegada / 100), horario_llegada %% 100,
      sep = "-"
    )),
    horario_salida_dt = ymd_hm(paste(
      anio, mes, dia,
      floor(horario_salida / 100), horario_salida %% 100,
      sep = "-"
    )),
    duracion_calculada = as.numeric(difftime(horario_llegada_dt, horario_salida_dt, units = "mins")),
    dif_duracion = duracion_calculada - tiempo_vuelo
  )

ggplot(vuelos_comparacion_tiempo, aes(x = dif_duracion, color = origen)) +
  geom_freqpoly() +
  labs(
    title = "Poligono de frencuente entre la diferencia de duración calculada y el tiempo de vuelo",
    x = "Diferencia de duraciones",
    y = "Frecuencia"
  ) +
  theme_minimal()
```
Comparando la diferencia de la estimación del tiempo de vuelo vs la duración real del vuelo, vemos que la distribución por aeropuerto es bastante homogénea entre si, en general, los tiempos de vuelo se reducen en hasta 200 minutos (probablemente por los cambios de zona horaria en Estados Unidos) mientras que se pueden demorar hasta 100 minutos más de lo previsto, hay un case when en la hora de llegada, debido a que el anio, mes y dia de la base de datos estan con respecto a la fecha de salida, y hay casos en donde pasar de las 23 hrs a las 00 hrs es un incremento de un dia en la fecha.

- ¿Cómo cambia la demora promedio durante el curso de un día? ¿Deberías usar `horario_salida` o `salida_programada`? ¿Por qué?
```{r, warning=FALSE}
vuelos_demora <- vuelos %>%
  filter(
    origen %in% c("JFK", "LGA", "EWR"),
    anio == 2013
  ) %>%
  mutate(
    hora_salida = ymd_hm(paste(
      anio, mes, dia,
      floor(horario_salida / 100), horario_salida %% 100,
      sep = "-"
    )),
    hora_salida_prog = ymd_hm(paste(
      anio, mes, case_when(
        (horario_salida < salida_programada) & (atraso_salida > 0) ~ dia - 1,
        TRUE ~ dia
      ),
      floor(salida_programada / 100), salida_programada %% 100,
      sep = "-"
    )),
    demora = as.numeric(difftime(hora_salida, hora_salida_prog, units = "mins")),
    hora = floor(horario_salida / 100)
  ) 

# Calcular la demora promedio por hora del día
demora_promedio <- vuelos_demora %>%
  group_by(hora) %>%
  summarise(demora_prom = mean(demora, na.rm = TRUE))

ggplot(demora_promedio, aes(x = hora, y = demora_prom)) +
  geom_line() +
  labs(
    title = "Demora promedio por hora del día",
    x = "Hora del día",
    y = "Demora promedio (minutos)"
  ) +
  scale_x_continuous(limits = c(0, 24), breaks = seq(0, 24, by = 1)) +
  theme_minimal()
```
Respecto a las demoras promedio por hora del día, se ve una clara tendencia, de hecho, bastante respalda por los gráficos previos, como los aeropuertos tienen estos tiempos de "inoperabilidad" entre 1:30 y 4:30 am es natural que incluso los promedios entre los tiempos de demora sean negativos (el vuelo comience antes) por que sean los primeros vuelos en operar (por lo que el aeropuerto todavia no es un caos), progresivamente los vuelos empizan a demorar a medida que el día avanza y el retraso de algunos vuelos puede hacer un efecto bola de nieve que retrace el resto, y finalmente si un vuelo es alcanzado en un periodo de "inoperabilidad" en promedio estos se trezan de 200 a 300 minutos, es decir, el tiempo suficiente para que el aeropuerto retome sus horarios de salida, para el calculo de la demora, es necesario tomar ambas variables horario_salida y salida_programada puesto que la diferencia de ellas nos da la demora, (de hecho hay otro case when porque cuando salida_programada es mayor que el horario_salida y el atraso es positivo, quiere decir que son los cambios de horario de 23:59 hrs a 00:00 hrs).

- ¿En qué día de la semana deberías salir si quieres minimizar las posibilidades de una demora?
```{r, warning=FALSE}
vuelos_dia_semana <- vuelos %>%
  filter(
    origen %in% c("JFK", "LGA", "EWR"),
    anio == 2013
  ) %>%
  mutate(
    dia_semana = factor(
      weekdays(as.Date(paste(anio, mes, dia, sep = "-"))),
    ),
    hora_salida = ymd_hm(paste(
      anio, mes, dia,
      floor(horario_salida / 100), horario_salida %% 100,
      sep = "-"
    )),
    hora_salida_prog = ymd_hm(paste(
      anio, mes, case_when(
        (horario_salida < salida_programada) & (atraso_salida > 0) ~ dia - 1,
        TRUE ~ dia
      ),
      floor(salida_programada / 100), salida_programada %% 100,
      sep = "-"
    )),
    demora = as.numeric(difftime(hora_salida, hora_salida_prog, units = "mins")),
  )

demora_dia_semana <- vuelos_dia_semana %>%
  group_by(dia_semana) %>%
  summarise(demora_prom = mean(demora, na.rm = TRUE))

ggplot(demora_dia_semana, aes(x = dia_semana, y = demora_prom)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(
    title = "Demora promedio por día de la semana",
    x = "Día de la semana",
    y = "Demora promedio (minutos)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Los vuelos en promedio se retrazan menos los sábados, y se demoran más los jueves.

- ¿Qué hace que la distribución de `diamantes$quilate` y `vuelos$salida_programada` sea similar?
```{r, warning=FALSE}
ggplot() +
  geom_histogram(
    data = diamantes, aes(x = quilate),
    bins = 12, fill = "skyblue",
    color = "black", alpha = 0.5
  ) +
  labs(
    title = "Distribucion de quilate",
    x = "Quilate",
    y = "Frecuencia"
  ) +
  theme_minimal()

ggplot() +
  geom_histogram(
    data = vuelos, aes(x = salida_programada),
    bins = 12, fill = "red",
    color = "black", alpha = 0.5
  ) +
  labs(
    title = "Distribucion de salida programada",
    x = "Salida Programada",
    y = "Frecuencia"
  ) +
  theme_minimal()
```
Las distribuciones entre las dos variables no parecen tener una similitud, la distribución asociada a la variable quilate tiene un perfil más similar a la exponencial mientras que la dist. asociada a la salida programada parece tener más perfil de una distribución uniforme o hipergeométrica, de cualquier manera, si estas tuvieran un perfil de distribución similar, esto no implicaria una causalidad ya que son dos experimentos diferentes que incluso uno no infiere en el otro.

- Confirma nuestra hipótesis de que las salidas programadas en los minutos 20-30 y 50-60 están casuadas por los vuelos programados que salen más temprano. Pista: crea una variable binaria que te diga si un vuelo tuvo o no demora.
```{r, warning=FALSE}
vuelos_demora_binaria <- vuelos %>%
  mutate(
    hora_salida = ymd_hm(paste(
      anio, mes, dia,
      floor(horario_salida / 100), horario_salida %% 100,
      sep = "-"
    )),
    hora_salida_prog = ymd_hm(paste(
      anio, mes, case_when(
        (horario_salida < salida_programada) & (atraso_salida > 0) ~ dia - 1,
        TRUE ~ dia
      ),
      floor(salida_programada / 100), salida_programada %% 100,
      sep = "-"
    )),
    demora = as.numeric(difftime(hora_salida, hora_salida_prog, units = "mins")),
    demora_binaria = ifelse(demora > 0, 1, 0),
    minutos_salida = (salida_programada %% 100),
    agrupados = cut(
      minutos_salida, 
      breaks = c(-Inf, 20, 30, 50, 60), 
      labels = c("0-20", "20-30", "30-50", "50-60")
    )
  ) %>%
  filter(
    !is.na(demora_binaria)
  )

ggplot() +
  geom_bar(
    data = vuelos_demora_binaria,
    aes(x = agrupados, fill = factor(demora_binaria)),
    position = "dodge"
  ) +
  labs(
    title = "Demoras en salidas programadas en minutos 20-30 y 50-60",
    x = "Minutos de salida",
    y = "Frecuencia",
    fill = "Tiene demora"
  ) +
  theme_minimal()

ggplot() +
  geom_bar(
    data = vuelos_demora_binaria,
    aes(x = minutos_salida, fill = factor(demora_binaria)),
    position = "dodge"
  ) +
  labs(
    title = "Demoras en salidas programadas en minutos 20-30 y 50-60",
    x = "Minutos de salida",
    y = "Frecuencia",
    fill = "Tiene demora"
  ) +
  theme_minimal()
```
Esta hipótesis se tendría que ver rechazada, las salidas programdas en los intervalos de minutos de 20-30 y 50-60 son de hecho los que menos demoras llegan a tener, lo que si suele apreciarse más es que todos los vuelos que sean divisibles por el número 5, son los que más demoras presentan.